{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Spell Check PhoBERT.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNRsDwmB1R9Awbwpe3xUjGA"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"1990d4cd3eb34f11b196c712c46fdc22":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_bc61f821e06c4e1cb3399dcc47798fd2","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_97673b013b9c44099be16882ecda04e4","IPY_MODEL_7324d83e4b024f06b9126a43b7d9b78c","IPY_MODEL_73bf6fe7be6d4631b570f148eea5c92d"]}},"bc61f821e06c4e1cb3399dcc47798fd2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"97673b013b9c44099be16882ecda04e4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_d41952be796e455098a5fdca4639f7bc","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_10fee89431034b18b27e092aa52022ac"}},"7324d83e4b024f06b9126a43b7d9b78c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_7c53b4a6e6c6477980e0dbf38531521d","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":895321,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":895321,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_238336a9ff164ad8a13c66c7588888a4"}},"73bf6fe7be6d4631b570f148eea5c92d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_33a4e54920e8419db5326ee0facc0009","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 874k/874k [00:00&lt;00:00, 1.86MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_1da66ac2ddc84bfda0cf723187ee9990"}},"d41952be796e455098a5fdca4639f7bc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"10fee89431034b18b27e092aa52022ac":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7c53b4a6e6c6477980e0dbf38531521d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"238336a9ff164ad8a13c66c7588888a4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"33a4e54920e8419db5326ee0facc0009":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"1da66ac2ddc84bfda0cf723187ee9990":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9666e1cddc764e11b9792752655bd018":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_2f98e7ad34fc46bcb4be40627c45cd59","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_793af1af214640d4899e1f7adf04b12f","IPY_MODEL_a1983f1d7a5a4744adcbe36d06074ee7","IPY_MODEL_be6fbb76a89048fcb52558a598b77f2d"]}},"2f98e7ad34fc46bcb4be40627c45cd59":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"793af1af214640d4899e1f7adf04b12f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_9ae4dc6e335f4e0ea2937e9a513e41ff","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_33eb99a294cc424e900475401304e297"}},"a1983f1d7a5a4744adcbe36d06074ee7":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_7682b9cdd6f9460fa9b4f64bac0f1cd9","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":557,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":557,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_68081ec0dc464dfaa73ec11053ea6af3"}},"be6fbb76a89048fcb52558a598b77f2d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_faf1b203d5d84db691607901edbacf70","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 557/557 [00:00&lt;00:00, 12.2kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_71151799826d4c38a0acd1754b6ee3af"}},"9ae4dc6e335f4e0ea2937e9a513e41ff":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"33eb99a294cc424e900475401304e297":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7682b9cdd6f9460fa9b4f64bac0f1cd9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"68081ec0dc464dfaa73ec11053ea6af3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"faf1b203d5d84db691607901edbacf70":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"71151799826d4c38a0acd1754b6ee3af":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7752a32cc2e1476c9c4efda170bf06bf":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_db36df7cff11401a91743b3ded8596a2","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_6e6b78473f5e4fcd87e7fd804539cb8c","IPY_MODEL_8e7e755d36294f43a5eafec2ffce4edb","IPY_MODEL_25434dbf082e4d7b9970bdb70733e038"]}},"db36df7cff11401a91743b3ded8596a2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6e6b78473f5e4fcd87e7fd804539cb8c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_79278134a3424da48ddf88bbfb79257f","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_1439b1f4dbee44009fabd70743278efb"}},"8e7e755d36294f43a5eafec2ffce4edb":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_8919a179b04a4ffdac7963b5aeb91943","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":542923308,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":542923308,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_94344260a53e4faaa9f932693d843422"}},"25434dbf082e4d7b9970bdb70733e038":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_2781c61641534ad3a29579c9c66a6f4f","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 518M/518M [00:14&lt;00:00, 35.4MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_10caad49118846dd8e9ae8550cd4dd8a"}},"79278134a3424da48ddf88bbfb79257f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"1439b1f4dbee44009fabd70743278efb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8919a179b04a4ffdac7963b5aeb91943":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"94344260a53e4faaa9f932693d843422":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2781c61641534ad3a29579c9c66a6f4f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"10caad49118846dd8e9ae8550cd4dd8a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"155c4b81324f4c539d70072647b3f37b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_359e1d2f9be44f49b1292f4b1c0b46ce","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_8718e03f0be54699bf5d65d34e8a9bfa","IPY_MODEL_f7c718bdfda54a96a18f9ff25c9bb843","IPY_MODEL_974c571f93a0478b826abf097dd22205"]}},"359e1d2f9be44f49b1292f4b1c0b46ce":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8718e03f0be54699bf5d65d34e8a9bfa":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_61b688f232e8450dbba4ce7fbd57851e","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ef30fdfb419d456398e0c61b3c8c4e84"}},"f7c718bdfda54a96a18f9ff25c9bb843":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_7833cc056c0e470bb8dfd47927cc6e42","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":8500,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":8500,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ee2e71f56bf8412f9bc3c735a8005e0b"}},"974c571f93a0478b826abf097dd22205":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_b2605371b23444c6a5a8a6856cfe5e23","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 8500/8500 [00:06&lt;00:00, 1480.43it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_4550b3f7b12e492b86217ac42cc8dad1"}},"61b688f232e8450dbba4ce7fbd57851e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"ef30fdfb419d456398e0c61b3c8c4e84":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7833cc056c0e470bb8dfd47927cc6e42":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"ee2e71f56bf8412f9bc3c735a8005e0b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b2605371b23444c6a5a8a6856cfe5e23":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"4550b3f7b12e492b86217ac42cc8dad1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5d76863eaa34404aa8bdc8e3e147af4c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_9913ee929bc448678faa39a89f7a2e2f","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_2457536add884440a54709d260ad5987","IPY_MODEL_8daf01f39ef94aad80da1a4f41280d9c","IPY_MODEL_974b21f39dba4dcbbcbfd064eb7359b9"]}},"9913ee929bc448678faa39a89f7a2e2f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2457536add884440a54709d260ad5987":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_6bfed3694a1040069156e6247d8eae4e","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Epoch 2 of 2: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_71f16166867a484b828226ad0fa53201"}},"8daf01f39ef94aad80da1a4f41280d9c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_68ef6c026aec42b2b5a8a9a317bd48ea","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":2,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":2,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_d5728a3dca3e490f8832a47147de4f1e"}},"974b21f39dba4dcbbcbfd064eb7359b9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_d6fef85d95e14dd0881a9dda627cacf6","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 2/2 [1:13:04&lt;00:00, 2190.15s/it]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_2f09420d33d94616a29efcce738a67a9"}},"6bfed3694a1040069156e6247d8eae4e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"71f16166867a484b828226ad0fa53201":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"68ef6c026aec42b2b5a8a9a317bd48ea":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"d5728a3dca3e490f8832a47147de4f1e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d6fef85d95e14dd0881a9dda627cacf6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"2f09420d33d94616a29efcce738a67a9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b1c4838f3abd453f98d734ca7244d2e8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_fc353600965e47eab14c9ea1079ce2f8","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_1eb4836fda0440c2b326767243e7bb11","IPY_MODEL_63d6f7f1c70f4db79755d6ec9e50ce5a","IPY_MODEL_c92e5f2a55af47c1af19dd6c30aa310e"]}},"fc353600965e47eab14c9ea1079ce2f8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"1eb4836fda0440c2b326767243e7bb11":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_9a892978cb2d4c329a4db83c5fd3b43c","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Epochs 1/2. Running Loss:    0.0194: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_cefbddaa7d7b478ca21f1db30f17bf36"}},"63d6f7f1c70f4db79755d6ec9e50ce5a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_9eb86705693449a29caf7ddaa557a9cf","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":67,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":67,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_530020a1038240479fd0f301bb143bd8"}},"c92e5f2a55af47c1af19dd6c30aa310e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_6dcdeaeebf7c4ab3952c49afce488068","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 67/67 [36:44&lt;00:00, 27.84s/it]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_d4cc420e455e4187aa0612602c704784"}},"9a892978cb2d4c329a4db83c5fd3b43c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"cefbddaa7d7b478ca21f1db30f17bf36":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9eb86705693449a29caf7ddaa557a9cf":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"530020a1038240479fd0f301bb143bd8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6dcdeaeebf7c4ab3952c49afce488068":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"d4cc420e455e4187aa0612602c704784":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"84eef620dc16401b85f54731339a6f14":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_9ef40418113040619dc845310d98e262","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_0a35785f9eac4249ae320407b6e24e35","IPY_MODEL_f372ffca12c047149a37f6ceee23ab5a","IPY_MODEL_c6c69ab369164613a8d39d925b2989f4"]}},"9ef40418113040619dc845310d98e262":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0a35785f9eac4249ae320407b6e24e35":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_8052b2d57e1d4cbcb3c2aa36a1742ec1","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Epochs 2/2. Running Loss:    0.0041: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_6795187af55a4722ac20732ff5b9bc2a"}},"f372ffca12c047149a37f6ceee23ab5a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_2b50363c89d141ed92ecfd759f54d168","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":67,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":67,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_54c217d4af0a4d0a998dbe720b6fc5fc"}},"c6c69ab369164613a8d39d925b2989f4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_f8448c6fd3c440e0a7543477dff3f8a2","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 67/67 [36:20&lt;00:00, 27.46s/it]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f5a183567eb54b658d8b9df6c091ae60"}},"8052b2d57e1d4cbcb3c2aa36a1742ec1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"6795187af55a4722ac20732ff5b9bc2a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2b50363c89d141ed92ecfd759f54d168":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"54c217d4af0a4d0a998dbe720b6fc5fc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f8448c6fd3c440e0a7543477dff3f8a2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"f5a183567eb54b658d8b9df6c091ae60":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"8HwgnPQVU6Yn","colab":{"base_uri":"https://localhost:8080/"},"outputId":"6e1d9708-00d1-45a0-bfc8-f0b53989a9e7","executionInfo":{"status":"ok","timestamp":1642307834390,"user_tz":-420,"elapsed":4731,"user":{"displayName":"Bảo Gia","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11624532628630192490"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/gdrive')\n"]},{"cell_type":"code","source":["!pip install transformers\n","!pip install torch\n","!pip install scikit-learn\n","!pip install fastBPE\n","!pip install fairseq\n","!pip install unidecode\n","!pip install underthesea\n","!pip install phased_lstm_keras \n","\n"],"metadata":{"id":"9H3siNpEVL7n"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import re\n","import os\n","import numpy as np\n","import torch\n","import pickle\n","import itertools\n","import underthesea\n","from tqdm import tqdm\n","from nltk import ngrams\n","import tensorflow as tf\n","from unidecode import unidecode\n","from tensorflow.keras import layers\n","from keras.models import Sequential\n","from fairseq.data import Dictionary\n","from tensorflow.keras.optimizers import Adam\n","from fairseq.models.roberta import RobertaModel\n","from fairseq.data.encoders.fastbpe import fastBPE\n","from sklearn.model_selection import train_test_split\n","from transformers import RobertaConfig,TFRobertaModel\n","\n","\n","\n","\n"],"metadata":{"id":"VJyRj7ooXHbd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Download Pretrained PhoBert\n","!wget https://public.vinai.io/PhoBERT_base_fairseq.tar.gz\n","!tar -xzvf PhoBERT_base_fairseq.tar.gz\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nZbYVsSD8NFa","executionInfo":{"status":"ok","timestamp":1642306610131,"user_tz":-420,"elapsed":38655,"user":{"displayName":"Bảo Gia","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11624532628630192490"}},"outputId":"ce038980-f63d-42e9-8a84-31f6e10807fd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["--2022-01-16 04:16:14--  https://public.vinai.io/PhoBERT_base_fairseq.tar.gz\n","Resolving public.vinai.io (public.vinai.io)... 13.226.52.126, 13.226.52.20, 13.226.52.43, ...\n","Connecting to public.vinai.io (public.vinai.io)|13.226.52.126|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 1243308020 (1.2G) [application/x-tar]\n","Saving to: ‘PhoBERT_base_fairseq.tar.gz’\n","\n","PhoBERT_base_fairse 100%[===================>]   1.16G  75.0MB/s    in 15s     \n","\n","2022-01-16 04:16:32 (77.6 MB/s) - ‘PhoBERT_base_fairseq.tar.gz’ saved [1243308020/1243308020]\n","\n","PhoBERT_base_fairseq/\n","PhoBERT_base_fairseq/bpe.codes\n","PhoBERT_base_fairseq/model.pt\n","PhoBERT_base_fairseq/dict.txt\n"]}]},{"cell_type":"code","source":["# Load dữ liệu từ file Data.pkl\n","data = pickle.load(open('/content/gdrive/MyDrive/Spell Check PhoBert/Data.pkl','rb'))\n","alphabet = '^[ _abcdefghijklmnopqrstuvwxyz0123456789áàảãạâấầẩẫậăắằẳẵặóòỏõọôốồổỗộơớờởỡợéèẻẽẹêếềểễệúùủũụưứừửữựíìỉĩịýỳỷỹỵđ!\\\"\\',\\-\\.:;?_\\(\\)]+$'\n","#data = data.replace(\"\\n\",\".\")\n","training_data = []\n","sentences = data.split(\"\\n\")\n","for j in tqdm(sentences):\n","      if len(j.split()) > 5 and re.match(alphabet, j.lower()):\n","          training_data.append(j)\n","print(training_data[0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RozVLgPVXeIe","executionInfo":{"status":"ok","timestamp":1642307908130,"user_tz":-420,"elapsed":16853,"user":{"displayName":"Bảo Gia","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11624532628630192490"}},"outputId":"ed6ad93a-6c60-4862-b2a7-ab373b0a6c21"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 377320/377320 [00:10<00:00, 34790.90it/s]"]},{"output_type":"stream","name":"stdout","text":["Do vậy, mở rộng cửa sổ tạo luồng không khí lưu thông, nhiệt độ phòng cao, có ánh nắng mặt trời sẽ giúp giảm đời sống virus., \n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"code","source":["# Lựa chọn các đoạn văn bản lớn năm từ\n","def extract_phrases(text):\n","    return re.findall(r'\\w[\\w ]+', text)\n","phrases = itertools.chain.from_iterable(extract_phrases(text) for text in training_data)\n","phrases = [p.strip() for p in phrases if len(p.split()) > 5]\n","def _save_pkl(path, obj):\n","  with open(path, 'wb') as f:\n","    pickle.dump(obj, f)\n","_save_pkl('phrases.pkl', phrases)\n","print(phrases[0:10])\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1642307950251,"user_tz":-420,"elapsed":4553,"user":{"displayName":"Bảo Gia","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11624532628630192490"}},"outputId":"cc0440b5-5bdd-49fe-dd75-8c0a05f73ab6","id":"U7eyxXIUeWLG"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['mở rộng cửa sổ tạo luồng không khí lưu thông', 'có ánh nắng mặt trời sẽ giúp giảm đời sống virus', 'Các chuyên gia khuyến cáo mỗi người nên tự ý thức giữ vệ sinh cá nhân', 'bên cạnh việc đeo khẩu trang', 'rửa tay thường xuyên bằng dung dịch sát khuẩn như xà phòng', 'có thể ngăn 44 các bệnh truyền nhiễm', 'Sau khi tiếp xúc với bề mặt công cộng', 'nên rửa tay và vệ sinh cá nhân kỹ để hạn chế việc mang vi khuẩn', 'bụi bẩn từ môi trường ngoài vào nhà ở', 'Với những đồ dùng cá nhân như điện thoại']\n"]}]},{"cell_type":"code","source":["# Hàm tạo lỗi cho các câu\n","alphabet = '^[ _abcdefghijklmnopqrstuvwxyz0123456789áàảãạâấầẩẫậăắằẳẵặóòỏõọôốồổỗộơớờởỡợéèẻẽẹêếềểễệúùủũụưứừửữựíìỉĩịýỳỷỹỵđ!\\\"\\',\\-\\.:;?_\\(\\)]+$'\n","letters=list(\"abcdefghijklmnopqrstuvwxyzáàảãạâấầẩẫậăắằẳẵặóòỏõọôốồổỗộơớờởỡợéèẻẽẹêếềểễệúùủũụưứừửữựíìỉĩịýỳỷỹỵđABCDEFGHIJKLMNOPQRSTUVWXYZÁÀẢÃẠÂẤẦẨẪẬĂẮẰẲẴẶÓÒỎÕỌÔỐỒỔỖỘƠỚỜỞỠỢÉÈẺẼẸÊẾỀỂỄỆÚÙỦŨỤƯỨỪỬỮỰÍÌỈĨỊÝỲỶỸỴĐ\")\n","letters2=list(\"abcdefghijklmnopqrstuvwxyz\")\n","telex={\"ă\":\"aw\",\"â\":\"aa\",\"á\":\"as\",\"à\":\"af\",\"ả\":\"ar\",\"ã\":\"ax\",\"ạ\":\"aj\",\"ắ\":\"aws\",\"ổ\":\"oor\",\"ỗ\":\"oox\",\"ộ\":\"ooj\",\"ơ\":\"ow\",\n","\"ằ\":\"awf\",\"ẳ\":\"awr\",\"ẵ\":\"awx\",\"ặ\":\"awj\",\"ó\":\"os\",\"ò\":\"of\",\"ỏ\":\"or\",\"õ\":\"ox\",\"ọ\":\"oj\",\"ô\":\"oo\",\"ố\":\"oos\",\"ồ\":\"oof\",\n","\"ớ\":\"ows\",\"ờ\":\"owf\",\"ở\":\"owr\",\"ỡ\":\"owx\",\"ợ\":\"owj\",\"é\":\"es\",\"è\":\"ef\",\"ẻ\":\"er\",\"ẽ\":\"ex\",\"ẹ\":\"ej\",\"ê\":\"ee\",\"ế\":\"ees\",\"ề\":\"eef\",\n","\"ể\":\"eer\",\"ễ\":\"eex\",\"ệ\":\"eej\",\"ú\":\"us\",\"ù\":\"uf\",\"ủ\":\"ur\",\"ũ\":\"ux\",\"ụ\":\"uj\",\"ư\":\"uw\",\"ứ\":\"uws\",\"ừ\":\"uwf\",\"ử\":\"uwr\",\"ữ\":\"uwx\",\n","\"ự\":\"uwj\",\"í\":\"is\",\"ì\":\"if\",\"ỉ\":\"ir\",\"ị\":\"ij\",\"ĩ\":\"ix\",\"ý\":\"ys\",\"ỳ\":\"yf\",\"ỷ\":\"yr\",\"ỵ\":\"yj\",\"đ\":\"dd\",\n","\"Ă\":\"Aw\",\"Â\":\"Aa\",\"Á\":\"As\",\"À\":\"Af\",\"Ả\":\"Ar\",\"Ã\":\"Ax\",\"Ạ\":\"Aj\",\"Ắ\":\"Aws\",\"Ổ\":\"Oor\",\"Ỗ\":\"Oox\",\"Ộ\":\"Ooj\",\"Ơ\":\"Ow\",\n","\"Ằ\":\"AWF\",\"Ẳ\":\"Awr\",\"Ẵ\":\"Awx\",\"Ặ\":\"Awj\",\"Ó\":\"Os\",\"Ò\":\"Of\",\"Ỏ\":\"Or\",\"Õ\":\"Ox\",\"Ọ\":\"Oj\",\"Ô\":\"Oo\",\"Ố\":\"Oos\",\"Ồ\":\"Oof\",\n","\"Ớ\":\"Ows\",\"Ờ\":\"Owf\",\"Ở\":\"Owr\",\"Ỡ\":\"Owx\",\"Ợ\":\"Owj\",\"É\":\"Es\",\"È\":\"Ef\",\"Ẻ\":\"Er\",\"Ẽ\":\"Ex\",\"Ẹ\":\"Ej\",\"Ê\":\"Ee\",\"Ế\":\"Ees\",\"Ề\":\"Eef\",\n","\"Ể\":\"Eer\",\"Ễ\":\"Eex\",\"Ệ\":\"Eej\",\"Ú\":\"Us\",\"Ù\":\"Uf\",\"Ủ\":\"Ur\",\"Ũ\":\"Ux\",\"Ụ\":\"Uj\",\"Ư\":\"Uw\",\"Ứ\":\"Uws\",\"Ừ\":\"Uwf\",\"Ử\":\"Uwr\",\"Ữ\":\"Uwx\",\n","\"Ự\":\"Uwj\",\"Í\":\"Is\",\"Ì\":\"If\",\"Ỉ\":\"Ir\",\"Ị\":\"Ij\",\"Ĩ\":\"Ix\",\"Ý\":\"Ys\",\"Ỳ\":\"Yf\",\"Ỷ\":\"Yr\",\"Ỵ\":\"Yj\",\"Đ\":\"Dd\"}\n","vni={\"ă\":\"a8\",\"â\":\"a6\",\"á\":\"a1\",\"à\":\"a2\",\"ả\":\"a3\",\"ã\":\"a4\",\"ạ\":\"a5\",\"ắ\":\"a81\",\"ổ\":\"o63\",\"ỗ\":\"o64\",\"ộ\":\"o65\",\"ơ\":\"o7\",\n","\"ằ\":\"a82\",\"ẳ\":\"a83\",\"ẵ\":\"a84\",\"ặ\":\"a85\",\"ó\":\"o1\",\"ò\":\"o2\",\"ỏ\":\"o3\",\"õ\":\"o4\",\"ọ\":\"o5\",\"ô\":\"o6\",\"ố\":\"o61\",\"ồ\":\"o62\",\n","\"ớ\":\"o71\",\"ờ\":\"o72\",\"ở\":\"o73\",\"ỡ\":\"o74\",\"ợ\":\"o75\",\"é\":\"e1\",\"è\":\"e2\",\"ẻ\":\"e3\",\"ẽ\":\"e4\",\"ẹ\":\"e5\",\"ê\":\"e6\",\"ế\":\"e61\",\"ề\":\"e62\",\n","\"ể\":\"e63\",\"ễ\":\"e64\",\"ệ\":\"e65\",\"ú\":\"u1\",\"ù\":\"u2\",\"ủ\":\"u3\",\"ũ\":\"u4\",\"ụ\":\"u5\",\"ư\":\"u7\",\"ứ\":\"u71\",\"ừ\":\"u72\",\"ử\":\"u73\",\"ữ\":\"u74\",\n","\"ự\":\"u75\",\"í\":\"i1\",\"ì\":\"i2\",\"ỉ\":\"i3\",\"ị\":\"i5\",\"ĩ\":\"i4\",\"ý\":\"y1\",\"ỳ\":\"y2\",\"ỷ\":\"y3\",\"ỵ\":\"y5\",\"đ\":\"d6\",\n","\"Ă\":\"A8\",\"Â\":\"A6\",\"Á\":\"A1\",\"À\":\"A2\",\"Ả\":\"A3\",\"Ã\":\"A4\",\"Ạ\":\"A5\",\"Ắ\":\"A81\",\"Ổ\":\"O63\",\"Ỗ\":\"O64\",\"Ộ\":\"O65\",\"Ơ\":\"O7\",\n","\"Ằ\":\"A82\",\"Ẳ\":\"A83\",\"Ẵ\":\"A84\",\"Ặ\":\"A85\",\"Ó\":\"O1\",\"Ò\":\"O2\",\"Ỏ\":\"O3\",\"Õ\":\"O4\",\"Ọ\":\"O5\",\"Ô\":\"O6\",\"Ố\":\"O61\",\"Ồ\":\"O62\",\n","\"Ớ\":\"O71\",\"Ờ\":\"O72\",\"Ở\":\"O73\",\"Ỡ\":\"O74\",\"Ợ\":\"O75\",\"É\":\"E1\",\"È\":\"E2\",\"Ẻ\":\"E3\",\"Ẽ\":\"E4\",\"Ẹ\":\"E5\",\"Ê\":\"E6\",\"Ế\":\"E61\",\"Ề\":\"E62\",\n","\"Ể\":\"E63\",\"Ễ\":\"E64\",\"Ệ\":\"E65\",\"Ú\":\"U1\",\"Ù\":\"U2\",\"Ủ\":\"U3\",\"Ũ\":\"U4\",\"Ụ\":\"U5\",\"Ư\":\"U7\",\"Ứ\":\"U71\",\"Ừ\":\"U72\",\"Ử\":\"U73\",\"Ữ\":\"U74\",\n","\"Ự\":\"U75\",\"Í\":\"I1\",\"Ì\":\"I2\",\"Ỉ\":\"I3\",\"Ị\":\"I5\",\"Ĩ\":\"I4\",\"Ý\":\"Y1\",\"Ỳ\":\"Y2\",\"Ỷ\":\"Y3\",\"Ỵ\":\"Y5\",\"Đ\":\"D6\"}\n","region={\"ẻ\":\"ẽ\",\"ẽ\":\"ẻ\",\"ũ\":\"ủ\",\"ủ\":\"ũ\",\"ã\":\"ả\",\"ả\":\"ã\",\"ỏ\":\"õ\",\"õ\":\"ỏ\",\"i\":\"j\"}\n","region2={\"s\":\"x\",\"l\":\"n\",\"n\":\"l\",\"x\":\"s\",\"d\":\"gi\",\"S\":\"X\",\"L\":\"N\",\"N\":\"L\",\"X\":\"S\",\"Gi\":\"D\",\"D\":\"Gi\"}\n","vowel=list(\"aeiouyáàảãạâấầẩẫậăắằẳẵặóòỏõọôốồổỗộơớờởỡợéèẻẽẹêếềểễệúùủũụưứừửữựíìỉĩịýỳỷỹỵ\")\n","\n","\n","def add_noise(sentence, pivot1,pivot2):\n","    noisy_sentence = \"\"\n","    i = 0\n","    while i < len(sentence):\n","        if sentence[i] not in letters:\n","            noisy_sentence+=sentence[i]\n","        else:  \n","            random = np.random.uniform(0,1,1)[0]   \n","            if random < pivot1:\n","                noisy_sentence+=(sentence[i])\n","            elif random<pivot2:\n","                if sentence[i] in telex.keys() and sentence[i] in vni.keys() and sentence[i] in region.keys():\n","                    random2=np.random.uniform(0,1,1)[0]\n","                    if random2<=0.5:\n","                        noisy_sentence+=telex[sentence[i]]\n","                    elif random2<0.7:\n","                        noisy_sentence += vni[sentence[i]]\n","                    elif random2<0.9:\n","                        noisy_sentence+=region[sentence[i]]\n","                    elif random2<0.95 :\n","                        noisy_sentence+=unidecode(sentence[i])\n","                    else:\n","                        noisy_sentence+=sentence[i]\n","                elif sentence[i] in telex.keys():#Lỗi Telex\n","                    random3=np.random.uniform(0,1,1)[0]\n","                    if random3<=0.5:\n","                        noisy_sentence+=telex[sentence[i]]\n","                    elif random3<0.9 :\n","                        noisy_sentence+=unidecode(sentence[i])                        \n","                    else:\n","                        noisy_sentence+=sentence[i]\n","                elif sentence[i] in vni.keys():#Lỗi VNI\n","                    random4=np.random.uniform(0,1,1)[0]\n","                    if random4<=0.6:\n","                        noisy_sentence+=vni[sentence[i]]\n","                    elif random4<0.95 :\n","                        noisy_sentence+=unidecode(sentence[i])                        \n","                    else:\n","                        noisy_sentence+=sentence[i]\n","                elif sentence[i] in region.keys(): #Sai dấu vùng miền\n","                    random5=np.random.uniform(0,1,1)[0]\n","                    if random5<=0.5:\n","                        noisy_sentence+=region[sentence[i]]\n","                    elif random5<0.9:\n","                        noisy_sentence+=unidecode(sentence[i])                        \n","                    else:\n","                        noisy_sentence+=sentence[i]\n","                elif i<len(sentence)-1 :\n","                    if sentence[i] in region2.keys() and (i==0 or sentence[i-1] not in letters) and sentence[i+1] in vowel:\n","                        random6=np.random.uniform(0,1,1)[0]\n","                        if random6<=0.9:\n","                            noisy_sentence+=region2[sentence[i]]\n","                        else:\n","                            noisy_sentence+=sentence[i]\n","                    else:\n","                        noisy_sentence+=sentence[i]\n","\n","            else:\n","                new_random = np.random.uniform(0,1,1)[0]\n","                if new_random <=0.33:\n","                    if i == (len(sentence) - 1):\n","                        continue\n","                    else:\n","                        noisy_sentence+=(sentence[i+1])\n","                        noisy_sentence+=(sentence[i])\n","                        i += 1\n","                elif new_random <= 0.66:\n","                    random_letter = np.random.choice(letters2, 1)[0]\n","                    noisy_sentence+=random_letter\n","                else:\n","                    pass\n","      \n","        i += 1\n","    return noisy_sentence\n"],"metadata":{"id":"4iwPirP24_Ap"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def gen_ngrams(words, n=5):\n","    return ngrams(words.split(), n)\n","list_ngrams = []\n","for p in tqdm(phrases):\n","    if not re.match(alphabet, p.lower()):\n","        continue\n","    for ngr in gen_ngrams(p, 5):\n","        if len(\" \".join(ngr)) < 30:\n","            list_ngrams.append(\" \".join(ngr))\n","            "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IsIMhWyJ6zbV","executionInfo":{"status":"ok","timestamp":1642307992851,"user_tz":-420,"elapsed":14044,"user":{"displayName":"Bảo Gia","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11624532628630192490"}},"outputId":"593fe9b7-59ce-406a-d615-a369aec6b4ab"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 706184/706184 [00:13<00:00, 50756.87it/s]\n"]}]},{"cell_type":"code","source":["\n","del phrases\n","del training_data\n","list_ngrams = list((list_ngrams))\n","print(list_ngrams[0:10])\n","print(len(list_ngrams))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZIX8pofc-WEV","executionInfo":{"status":"ok","timestamp":1642307995983,"user_tz":-420,"elapsed":386,"user":{"displayName":"Bảo Gia","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11624532628630192490"}},"outputId":"d4056d7a-91d6-48e9-d9e5-5dc43d811a2d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['mở rộng cửa sổ tạo', 'rộng cửa sổ tạo luồng', 'cửa sổ tạo luồng không', 'sổ tạo luồng không khí', 'tạo luồng không khí lưu', 'luồng không khí lưu thông', 'có ánh nắng mặt trời', 'ánh nắng mặt trời sẽ', 'nắng mặt trời sẽ giúp', 'mặt trời sẽ giúp giảm']\n","6316221\n"]}]},{"cell_type":"code","source":["print(add_noise('thành phố như hiện nay',0.94,0.985))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1e-PLew9HJXd","executionInfo":{"status":"ok","timestamp":1642267018744,"user_tz":-420,"elapsed":34,"user":{"displayName":"Bảo Gia","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11624532628630192490"}},"outputId":"7c47b1ed-20f6-402a-b427-68b670baef20"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["thành phố như hiện nay\n"]}]},{"cell_type":"code","source":["# Load model PhoBert\n","phoBERT = RobertaModel.from_pretrained('PhoBERT_base_fairseq', checkpoint_file='model.pt')\n","phoBERT.eval()\n","class BPE():\n","  bpe_codes = 'PhoBERT_base_fairseq/bpe.codes'\n","args = BPE()\n","phoBERT.bpe = fastBPE(args) #Incorporate the BPE encoder into PhoBERT\n"],"metadata":{"id":"e_hrZWuQGCeh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data_train, data_val = train_test_split(list_ngrams[:10000],test_size=0.15, random_state=42)\n","#Tạo ra một cặp câu lỗi và câu bình thường\n","train_data=[]\n","for i in tqdm(range(len(data_train))):\n","    double = []\n","    double.insert(0,add_noise(data_train[i],0.9,0.95))\n","    double.append(data_train[i])\n","    train_data.append(double)\n","eval_data=[]\n","for i in tqdm(range(len(data_val)):\n","    double = []\n","    double.insert(0,add_noise(data_val[i],0.9,0.95))\n","    double.append(data_val[i])\n","    eval_data.append(double)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tyy4IxLGJgjL","executionInfo":{"status":"ok","timestamp":1642308012767,"user_tz":-420,"elapsed":1462,"user":{"displayName":"Bảo Gia","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11624532628630192490"}},"outputId":"e1394c7a-14b1-41a4-82f5-0ee9b4cbcb5d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 8500/8500 [00:01<00:00, 7193.17it/s]\n"]}]},{"cell_type":"code","source":["# Encode sent in list-gram\n","max_sequence_length = 40 \n","def convert_lines(lines, vocab, bpe):\n","  '''\n","  lines: list các văn bản input\n","  vocab: từ điển dùng để encoding subwords\n","  bpe: \n","  '''\n","  # Khởi tạo ma trận output\n","  outputs = np.zeros((len(lines), max_sequence_length), dtype=np.int32) # --> shape (number_lines, max_seq_len)\n","  # Index của các token cls (đầu câu), eos (cuối câu), padding (padding token)\n","  cls_id = 0\n","  eos_id = 2\n","  pad_id = 1\n","\n","  for idx, row in enumerate(lines): \n","    # Mã hóa subwords theo byte pair encoding(bpe)\n","    subwords = bpe.encode('<s> '+ row +' </s>')\n","    input_ids = vocab.encode_line(subwords, append_eos=False, add_if_not_exist=False).long().tolist()\n","    # Truncate input nếu độ dài vượt quá max_seq_len\n","    if len(input_ids) > max_sequence_length: \n","      input_ids = input_ids[:max_sequence_length] \n","      input_ids[-1] = eos_id\n","    else:\n","      # Padding nếu độ dài câu chưa bằng max_seq_len\n","      input_ids = input_ids + [pad_id, ]*(max_sequence_length - len(input_ids))\n","    \n","    outputs[idx,:] = np.array(input_ids)\n","  return outputs\n","vocab = Dictionary()\n","vocab.add_from_file(\"PhoBERT_base_fairseq/dict.txt\")\n","train_dataset = []\n","print(train_data[1])\n","for i in tqdm(range(len(train_data))):\n","  [x1,x2] = convert_lines(train_data[i],vocab,phoBERT.bpe)\n","  train_dataset.append([x1,x2])\n","# print(train_dataset[1])\n","# print('x1 tensor encode: {}, shape: {}'.format(train_dataset[1][0][:10], train_dataset[1][0].size))\n","# print('x1 tensor decode: ', phoBERT.decode(torch.tensor(train_dataset[1][0]))[:103])\n","# print('x2 tensor encode: {}, shape: {}'.format(train_dataset[1][1][:10], train_dataset[1][1].size))\n","# print('x2 tensor decode: ', phoBERT.decode(torch.tensor(train_dataset[1][1]))[:103])\n","# lines = ['Học_sinh được nghỉ học bắt dầu từ tháng 3 để tránh dịch covid-19', 'số lượng ca nhiễm bệnh đã giảm bắt đầu từ tháng 5 nhờ biện pháp mạnh tay']\n","# [x1, x2] = convert_lines(lines, vocab, phoBERT.bpe)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-Insps-5Ij2O","executionInfo":{"status":"ok","timestamp":1642309543177,"user_tz":-420,"elapsed":2285,"user":{"displayName":"Bảo Gia","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11624532628630192490"}},"outputId":"0090b078-8c08-4788-860c-d641ad3d0b29"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['rộng cửa sổ tạo luog', 'rộng cửa sổ tạo luồng']\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 8500/8500 [00:01<00:00, 4725.42it/s]\n"]}]},{"cell_type":"code","source":["# Tạo DataLoader để quản lý dữ liệu đưa vào huấn luyện\n","BATCH_SIZE=128\n","for x,y in train_dataset:\n","  dataset = torch.utils.data.TensorDataset(torch.tensor(x,dtype=torch.long), torch.tensor(y,dtype=torch.long))\n","  dataset = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)"],"metadata":{"id":"DxOYb0xRQhum"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from transformers import BertTokenizer, BertModel, BertForMaskedLM\n","tokenizer = BertTokenizer.from_pretrained('vinai/phobert-base')\n","model = BertForMaskedLM.from_pretrained('vinai/phobert-base')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":315,"referenced_widgets":["1990d4cd3eb34f11b196c712c46fdc22","bc61f821e06c4e1cb3399dcc47798fd2","97673b013b9c44099be16882ecda04e4","7324d83e4b024f06b9126a43b7d9b78c","73bf6fe7be6d4631b570f148eea5c92d","d41952be796e455098a5fdca4639f7bc","10fee89431034b18b27e092aa52022ac","7c53b4a6e6c6477980e0dbf38531521d","238336a9ff164ad8a13c66c7588888a4","33a4e54920e8419db5326ee0facc0009","1da66ac2ddc84bfda0cf723187ee9990","9666e1cddc764e11b9792752655bd018","2f98e7ad34fc46bcb4be40627c45cd59","793af1af214640d4899e1f7adf04b12f","a1983f1d7a5a4744adcbe36d06074ee7","be6fbb76a89048fcb52558a598b77f2d","9ae4dc6e335f4e0ea2937e9a513e41ff","33eb99a294cc424e900475401304e297","7682b9cdd6f9460fa9b4f64bac0f1cd9","68081ec0dc464dfaa73ec11053ea6af3","faf1b203d5d84db691607901edbacf70","71151799826d4c38a0acd1754b6ee3af","7752a32cc2e1476c9c4efda170bf06bf","db36df7cff11401a91743b3ded8596a2","6e6b78473f5e4fcd87e7fd804539cb8c","8e7e755d36294f43a5eafec2ffce4edb","25434dbf082e4d7b9970bdb70733e038","79278134a3424da48ddf88bbfb79257f","1439b1f4dbee44009fabd70743278efb","8919a179b04a4ffdac7963b5aeb91943","94344260a53e4faaa9f932693d843422","2781c61641534ad3a29579c9c66a6f4f","10caad49118846dd8e9ae8550cd4dd8a"]},"id":"kr_Rm-AT91IV","executionInfo":{"status":"ok","timestamp":1642309054142,"user_tz":-420,"elapsed":21295,"user":{"displayName":"Bảo Gia","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11624532628630192490"}},"outputId":"cbe311cc-904f-4651-e177-4033c8e781dc"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1990d4cd3eb34f11b196c712c46fdc22","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/874k [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9666e1cddc764e11b9792752655bd018","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/557 [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n","The tokenizer class you load from this checkpoint is 'PhobertTokenizer'. \n","The class this function is called from is 'BertTokenizer'.\n","Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","You are using a model of type roberta to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7752a32cc2e1476c9c4efda170bf06bf","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/518M [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at vinai/phobert-base were not used when initializing BertForMaskedLM: ['roberta.encoder.layer.11.attention.self.query.weight', 'roberta.encoder.layer.3.output.LayerNorm.bias', 'roberta.encoder.layer.4.intermediate.dense.weight', 'roberta.encoder.layer.8.attention.output.dense.weight', 'roberta.encoder.layer.11.output.LayerNorm.bias', 'roberta.encoder.layer.2.attention.output.dense.bias', 'roberta.encoder.layer.0.intermediate.dense.bias', 'roberta.encoder.layer.2.output.dense.weight', 'roberta.encoder.layer.3.intermediate.dense.weight', 'roberta.encoder.layer.10.output.dense.bias', 'roberta.encoder.layer.11.attention.output.LayerNorm.bias', 'roberta.encoder.layer.9.intermediate.dense.weight', 'roberta.encoder.layer.11.output.LayerNorm.weight', 'roberta.encoder.layer.10.output.dense.weight', 'roberta.encoder.layer.7.attention.self.key.weight', 'roberta.encoder.layer.7.output.LayerNorm.bias', 'roberta.encoder.layer.1.intermediate.dense.weight', 'roberta.encoder.layer.9.attention.self.key.bias', 'roberta.encoder.layer.3.attention.self.value.weight', 'roberta.encoder.layer.4.attention.self.query.weight', 'roberta.encoder.layer.8.attention.self.value.weight', 'roberta.encoder.layer.5.attention.self.query.bias', 'roberta.encoder.layer.1.attention.self.query.weight', 'roberta.encoder.layer.9.output.LayerNorm.weight', 'roberta.encoder.layer.10.output.LayerNorm.bias', 'roberta.encoder.layer.3.output.dense.weight', 'roberta.embeddings.position_embeddings.weight', 'roberta.encoder.layer.0.attention.self.value.bias', 'roberta.encoder.layer.1.output.LayerNorm.weight', 'roberta.encoder.layer.1.output.LayerNorm.bias', 'roberta.encoder.layer.7.attention.self.query.bias', 'roberta.encoder.layer.5.intermediate.dense.bias', 'roberta.encoder.layer.3.attention.self.key.weight', 'roberta.encoder.layer.4.attention.self.query.bias', 'roberta.encoder.layer.5.output.dense.weight', 'roberta.encoder.layer.9.attention.self.key.weight', 'roberta.encoder.layer.6.attention.self.value.bias', 'roberta.encoder.layer.10.attention.self.key.bias', 'roberta.encoder.layer.1.attention.output.LayerNorm.bias', 'roberta.encoder.layer.4.intermediate.dense.bias', 'roberta.encoder.layer.2.output.dense.bias', 'roberta.encoder.layer.7.attention.self.key.bias', 'roberta.encoder.layer.7.attention.output.LayerNorm.weight', 'roberta.encoder.layer.11.intermediate.dense.weight', 'roberta.encoder.layer.9.attention.self.query.bias', 'roberta.encoder.layer.1.attention.output.dense.weight', 'roberta.encoder.layer.2.output.LayerNorm.weight', 'roberta.encoder.layer.5.attention.output.LayerNorm.weight', 'roberta.encoder.layer.2.intermediate.dense.bias', 'lm_head.bias', 'roberta.encoder.layer.3.attention.output.dense.weight', 'roberta.encoder.layer.9.attention.output.dense.weight', 'roberta.encoder.layer.8.intermediate.dense.bias', 'roberta.encoder.layer.3.attention.output.dense.bias', 'roberta.encoder.layer.7.attention.output.dense.weight', 'roberta.encoder.layer.1.attention.self.value.weight', 'roberta.encoder.layer.0.output.dense.bias', 'roberta.encoder.layer.5.output.LayerNorm.weight', 'roberta.encoder.layer.6.intermediate.dense.weight', 'roberta.encoder.layer.8.intermediate.dense.weight', 'roberta.encoder.layer.8.output.dense.bias', 'roberta.encoder.layer.6.intermediate.dense.bias', 'roberta.encoder.layer.6.output.dense.bias', 'roberta.embeddings.position_ids', 'roberta.encoder.layer.4.attention.output.dense.bias', 'roberta.encoder.layer.8.attention.self.key.bias', 'roberta.encoder.layer.11.intermediate.dense.bias', 'roberta.encoder.layer.3.attention.self.key.bias', 'roberta.encoder.layer.4.attention.output.LayerNorm.weight', 'roberta.encoder.layer.4.output.LayerNorm.bias', 'roberta.encoder.layer.6.attention.output.dense.weight', 'roberta.encoder.layer.5.attention.self.value.weight', 'roberta.embeddings.word_embeddings.weight', 'roberta.encoder.layer.10.attention.self.value.bias', 'roberta.encoder.layer.10.intermediate.dense.weight', 'roberta.encoder.layer.10.attention.self.query.bias', 'roberta.encoder.layer.7.attention.output.dense.bias', 'roberta.encoder.layer.7.output.dense.weight', 'roberta.encoder.layer.8.attention.self.query.bias', 'roberta.encoder.layer.8.output.LayerNorm.bias', 'roberta.encoder.layer.1.attention.self.value.bias', 'roberta.encoder.layer.4.output.dense.bias', 'roberta.encoder.layer.0.intermediate.dense.weight', 'roberta.encoder.layer.11.attention.self.value.bias', 'roberta.encoder.layer.4.attention.self.key.bias', 'roberta.encoder.layer.4.output.dense.weight', 'roberta.encoder.layer.0.attention.self.key.bias', 'roberta.encoder.layer.7.intermediate.dense.weight', 'lm_head.decoder.weight', 'roberta.embeddings.token_type_embeddings.weight', 'roberta.encoder.layer.0.attention.self.query.bias', 'roberta.encoder.layer.2.attention.self.key.bias', 'roberta.encoder.layer.8.output.dense.weight', 'roberta.encoder.layer.4.attention.self.value.bias', 'roberta.encoder.layer.4.attention.self.value.weight', 'roberta.encoder.layer.8.attention.self.key.weight', 'roberta.encoder.layer.10.attention.self.value.weight', 'roberta.encoder.layer.0.output.dense.weight', 'roberta.encoder.layer.9.attention.output.dense.bias', 'roberta.encoder.layer.2.attention.output.LayerNorm.bias', 'roberta.encoder.layer.2.attention.self.key.weight', 'roberta.encoder.layer.11.attention.output.dense.bias', 'roberta.encoder.layer.1.attention.output.LayerNorm.weight', 'roberta.encoder.layer.7.attention.self.value.weight', 'roberta.encoder.layer.5.attention.self.key.weight', 'roberta.encoder.layer.6.attention.self.query.bias', 'roberta.encoder.layer.2.output.LayerNorm.bias', 'roberta.encoder.layer.9.attention.output.LayerNorm.bias', 'roberta.encoder.layer.11.output.dense.bias', 'roberta.encoder.layer.2.attention.self.query.bias', 'roberta.encoder.layer.2.intermediate.dense.weight', 'roberta.encoder.layer.4.attention.self.key.weight', 'roberta.encoder.layer.9.output.dense.weight', 'roberta.encoder.layer.0.output.LayerNorm.weight', 'roberta.encoder.layer.2.attention.self.value.bias', 'roberta.encoder.layer.3.attention.self.query.weight', 'roberta.encoder.layer.10.attention.output.dense.bias', 'roberta.encoder.layer.1.attention.self.key.bias', 'roberta.encoder.layer.6.attention.self.key.bias', 'roberta.encoder.layer.9.output.dense.bias', 'roberta.encoder.layer.4.attention.output.LayerNorm.bias', 'roberta.encoder.layer.10.output.LayerNorm.weight', 'roberta.encoder.layer.8.output.LayerNorm.weight', 'roberta.encoder.layer.0.attention.output.LayerNorm.bias', 'roberta.encoder.layer.9.attention.self.value.bias', 'roberta.encoder.layer.6.attention.self.value.weight', 'roberta.encoder.layer.10.attention.output.LayerNorm.weight', 'roberta.encoder.layer.5.attention.self.query.weight', 'roberta.encoder.layer.3.attention.self.value.bias', 'roberta.encoder.layer.9.attention.self.query.weight', 'roberta.encoder.layer.2.attention.output.LayerNorm.weight', 'lm_head.decoder.bias', 'roberta.encoder.layer.6.output.LayerNorm.weight', 'roberta.encoder.layer.7.output.LayerNorm.weight', 'roberta.encoder.layer.6.output.LayerNorm.bias', 'roberta.encoder.layer.7.attention.self.query.weight', 'roberta.encoder.layer.3.attention.output.LayerNorm.weight', 'roberta.encoder.layer.11.attention.output.LayerNorm.weight', 'roberta.encoder.layer.8.attention.output.dense.bias', 'roberta.encoder.layer.5.attention.self.value.bias', 'roberta.encoder.layer.0.attention.output.dense.bias', 'roberta.encoder.layer.4.output.LayerNorm.weight', 'roberta.encoder.layer.2.attention.self.value.weight', 'roberta.encoder.layer.7.attention.self.value.bias', 'roberta.encoder.layer.1.attention.output.dense.bias', 'roberta.encoder.layer.8.attention.self.query.weight', 'roberta.encoder.layer.8.attention.self.value.bias', 'roberta.encoder.layer.10.attention.output.dense.weight', 'roberta.encoder.layer.1.attention.self.query.bias', 'roberta.encoder.layer.1.intermediate.dense.bias', 'roberta.encoder.layer.5.output.LayerNorm.bias', 'roberta.encoder.layer.0.output.LayerNorm.bias', 'roberta.encoder.layer.1.output.dense.bias', 'roberta.encoder.layer.8.attention.output.LayerNorm.bias', 'roberta.encoder.layer.11.attention.output.dense.weight', 'roberta.encoder.layer.6.attention.output.LayerNorm.weight', 'roberta.encoder.layer.0.attention.output.dense.weight', 'roberta.encoder.layer.8.attention.output.LayerNorm.weight', 'roberta.encoder.layer.0.attention.self.value.weight', 'roberta.encoder.layer.9.attention.self.value.weight', 'roberta.encoder.layer.11.attention.self.key.weight', 'roberta.encoder.layer.9.output.LayerNorm.bias', 'lm_head.dense.bias', 'roberta.encoder.layer.6.attention.output.dense.bias', 'roberta.encoder.layer.7.attention.output.LayerNorm.bias', 'roberta.encoder.layer.0.attention.output.LayerNorm.weight', 'roberta.encoder.layer.3.output.LayerNorm.weight', 'roberta.encoder.layer.0.attention.self.key.weight', 'roberta.encoder.layer.6.attention.self.key.weight', 'roberta.encoder.layer.3.attention.output.LayerNorm.bias', 'roberta.encoder.layer.5.attention.output.dense.weight', 'roberta.encoder.layer.10.attention.self.query.weight', 'roberta.encoder.layer.6.attention.self.query.weight', 'roberta.encoder.layer.10.attention.self.key.weight', 'roberta.encoder.layer.4.attention.output.dense.weight', 'roberta.encoder.layer.5.attention.self.key.bias', 'roberta.encoder.layer.2.attention.output.dense.weight', 'roberta.encoder.layer.11.output.dense.weight', 'lm_head.layer_norm.weight', 'roberta.encoder.layer.9.attention.output.LayerNorm.weight', 'roberta.encoder.layer.6.output.dense.weight', 'roberta.encoder.layer.11.attention.self.key.bias', 'roberta.encoder.layer.3.intermediate.dense.bias', 'roberta.encoder.layer.5.attention.output.dense.bias', 'roberta.encoder.layer.7.intermediate.dense.bias', 'roberta.encoder.layer.10.intermediate.dense.bias', 'roberta.encoder.layer.11.attention.self.query.bias', 'roberta.encoder.layer.5.attention.output.LayerNorm.bias', 'roberta.encoder.layer.9.intermediate.dense.bias', 'roberta.encoder.layer.11.attention.self.value.weight', 'roberta.encoder.layer.2.attention.self.query.weight', 'roberta.encoder.layer.1.output.dense.weight', 'roberta.encoder.layer.3.output.dense.bias', 'roberta.encoder.layer.3.attention.self.query.bias', 'roberta.encoder.layer.5.output.dense.bias', 'roberta.encoder.layer.0.attention.self.query.weight', 'roberta.encoder.layer.5.intermediate.dense.weight', 'roberta.encoder.layer.6.attention.output.LayerNorm.bias', 'roberta.encoder.layer.7.output.dense.bias', 'lm_head.dense.weight', 'roberta.embeddings.LayerNorm.bias', 'roberta.encoder.layer.1.attention.self.key.weight', 'roberta.encoder.layer.10.attention.output.LayerNorm.bias', 'roberta.embeddings.LayerNorm.weight', 'lm_head.layer_norm.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForMaskedLM were not initialized from the model checkpoint at vinai/phobert-base and are newly initialized: ['encoder.layer.7.attention.self.key.weight', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'embeddings.LayerNorm.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.7.attention.output.dense.weight', 'cls.predictions.decoder.weight', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.0.output.dense.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.0.output.dense.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.8.output.dense.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.0.attention.output.dense.bias', 'embeddings.position_embeddings.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.11.output.dense.weight', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.3.output.dense.weight', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.8.output.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.4.output.dense.weight', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.5.attention.self.value.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.1.output.dense.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.4.output.dense.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.7.output.dense.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.6.attention.self.query.bias', 'cls.predictions.transform.dense.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.4.attention.self.key.bias', 'cls.predictions.transform.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.9.output.dense.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.10.output.LayerNorm.weight', 'cls.predictions.bias', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.2.attention.self.query.bias', 'embeddings.LayerNorm.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.5.intermediate.dense.bias', 'embeddings.token_type_embeddings.weight', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.10.attention.output.dense.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}]},{"cell_type":"code","source":["# input_ids = []\n","# attention_masks = []\n","\n","# # # For every sentence...\n","# # for sent in sentences:\n","# #     # `encode_plus` will:\n","# #     #   (1) Tokenize the sentence.\n","# #     #   (2) Prepend the `[CLS]` token to the start.\n","# #     #   (3) Append the `[SEP]` token to the end.\n","# #     #   (4) Map tokens to their IDs.\n","# #     #   (5) Pad or truncate the sentence to `max_length`\n","# #     #   (6) Create attention masks for [PAD] tokens.\n","# #     encoded_dict = tokenizer.encode_plus(\n","# #                         sent,                      # Sentence to encode.\n","# #                         add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n","# #                         max_length = 64,           # Pad & truncate all sentences.\n","# #                         pad_to_max_length = True,\n","# #                         return_attention_mask = True,   # Construct attn. masks.\n","# #                         return_tensors = 'pt',     # Return pytorch tensors.\n","# #                    )\n","    \n","# #     # Add the encoded sentence to the list.    \n","# #     input_ids.append(encoded_dict['input_ids'])\n","    \n","# #     # And its attention mask (simply differentiates padding from non-padding).\n","# #     attention_masks.append(encoded_dict['attention_mask'])\n","# encoded_dict = tokenizer.encode_plus(train_data[0][0],                      # Sentence to encode.\n","#                          add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n","#                          max_length = 40,           # Pad & truncate all sentences.\n","#                          pad_to_max_length = True,\n","#                          return_attention_mask = True, )  # Construct attn. masks.)\n","\n","# # Convert the lists into tensors.\n","# input_ids = torch.cat(input_ids, dim=0)\n","# attention_masks = torch.cat(attention_masks, dim=0)"],"metadata":{"id":"I7Yyv6LDDkb9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["del train_df,eval_df"],"metadata":{"id":"s4cwgUpqNuUI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Huấn luyện thử bằng thư viện SimpleTransformers với model Seq2Seq\n","import logging\n","import pandas as pd\n","from simpletransformers.seq2seq import Seq2SeqModel\n","\n","logging.basicConfig(level=logging.INFO)\n","transformers_logger = logging.getLogger(\"transformers\")\n","transformers_logger.setLevel(logging.WARNING)\n","\n","train_df = pd.DataFrame(train_data, columns=[\"input_text\", \"target_text\"])\n","\n","eval_df = pd.DataFrame(eval_data, columns=[\"input_text\", \"target_text\"])\n","\n"],"metadata":{"id":"nba9JZ6-R6-0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1642275028259,"user_tz":-420,"elapsed":1588,"user":{"displayName":"Bảo Gia","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11624532628630192490"}},"outputId":"d1522450-bd49-4434-cddb-c7df6f470eeb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 8500/8500 [00:01<00:00, 6758.29it/s]"]},{"output_type":"stream","name":"stdout","text":["                    input_text              target_text\n","0            ở rộng cửa sổ tạo       mở rộng cửa sổ tạo\n","1        rộng cửa sổ gạo luồng    rộng cửa sổ tạo luồng\n","2       cửa sổ tajo luồn không   cửa sổ tạo luồng không\n","3       sổ tạo luồng không khí   sổ tạo luồng không khí\n","4      tạo luồng kôhng khí lưu  tạo luồng không khí lưu\n","...                        ...                      ...\n","8495  thơm nhiều hosa thực vật  thơm nhiều hóa thực vật\n","8496     nhiều hóa thực vật và    nhiều hóa thực vật và\n","8497      hóa thực vật và tinh     hóa thực vật và tinh\n","8498      thực vật và tinh dầu     thực vật và tinh dầu\n","8499       vật và tinh dầu bpc      vật và tinh dầu bạc\n","\n","[8500 rows x 2 columns]\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"code","source":["# Huấn luyện thử bằng thư viện SimpleTransformers với model Seq2Seq\n","model_args = {\n","    \"reprocess_input_data\": True,\n","    \"overwrite_output_dir\": True,\n","    \"max_seq_length\": 10,\n","    \"train_batch_size\": 128,\n","    \"num_train_epochs\": 2,\n","    \"save_eval_checkpoints\": False,\n","    \"save_model_every_epoch\": False,\n","    \"evaluate_generated_text\": True,\n","    \"evaluate_during_training_verbose\": True,\n","    \"use_multiprocessing\": False,\n","    \"max_length\": 40,\n","    \"manual_seed\": 4,\n","}\n","\n","encoder_type = \"roberta\"\n","\n","model = Seq2SeqModel(\n","    encoder_type,\n","    \"roberta-base\",\n","    \"vinai/phobert-base\",\n","    args=model_args,\n","    use_cuda=False,\n",")\n","\n","model.train_model(train_df)\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":421,"referenced_widgets":["155c4b81324f4c539d70072647b3f37b","359e1d2f9be44f49b1292f4b1c0b46ce","8718e03f0be54699bf5d65d34e8a9bfa","f7c718bdfda54a96a18f9ff25c9bb843","974c571f93a0478b826abf097dd22205","61b688f232e8450dbba4ce7fbd57851e","ef30fdfb419d456398e0c61b3c8c4e84","7833cc056c0e470bb8dfd47927cc6e42","ee2e71f56bf8412f9bc3c735a8005e0b","b2605371b23444c6a5a8a6856cfe5e23","4550b3f7b12e492b86217ac42cc8dad1","5d76863eaa34404aa8bdc8e3e147af4c","9913ee929bc448678faa39a89f7a2e2f","2457536add884440a54709d260ad5987","8daf01f39ef94aad80da1a4f41280d9c","974b21f39dba4dcbbcbfd064eb7359b9","6bfed3694a1040069156e6247d8eae4e","71f16166867a484b828226ad0fa53201","68ef6c026aec42b2b5a8a9a317bd48ea","d5728a3dca3e490f8832a47147de4f1e","d6fef85d95e14dd0881a9dda627cacf6","2f09420d33d94616a29efcce738a67a9","b1c4838f3abd453f98d734ca7244d2e8","fc353600965e47eab14c9ea1079ce2f8","1eb4836fda0440c2b326767243e7bb11","63d6f7f1c70f4db79755d6ec9e50ce5a","c92e5f2a55af47c1af19dd6c30aa310e","9a892978cb2d4c329a4db83c5fd3b43c","cefbddaa7d7b478ca21f1db30f17bf36","9eb86705693449a29caf7ddaa557a9cf","530020a1038240479fd0f301bb143bd8","6dcdeaeebf7c4ab3952c49afce488068","d4cc420e455e4187aa0612602c704784","84eef620dc16401b85f54731339a6f14","9ef40418113040619dc845310d98e262","0a35785f9eac4249ae320407b6e24e35","f372ffca12c047149a37f6ceee23ab5a","c6c69ab369164613a8d39d925b2989f4","8052b2d57e1d4cbcb3c2aa36a1742ec1","6795187af55a4722ac20732ff5b9bc2a","2b50363c89d141ed92ecfd759f54d168","54c217d4af0a4d0a998dbe720b6fc5fc","f8448c6fd3c440e0a7543477dff3f8a2","f5a183567eb54b658d8b9df6c091ae60"]},"id":"I0QmukEtak50","executionInfo":{"status":"ok","timestamp":1642279467100,"user_tz":-420,"elapsed":4418819,"user":{"displayName":"Bảo Gia","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11624532628630192490"}},"outputId":"c50777ba-8d78-45dc-db8a-2692b47b22ab"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaForCausalLM were not initialized from the model checkpoint at vinai/phobert-base and are newly initialized: ['roberta.encoder.layer.6.crossattention.self.query.weight', 'roberta.encoder.layer.2.crossattention.self.key.bias', 'roberta.encoder.layer.11.crossattention.output.dense.weight', 'roberta.encoder.layer.11.crossattention.self.key.weight', 'roberta.encoder.layer.0.crossattention.self.key.bias', 'roberta.encoder.layer.1.crossattention.self.query.weight', 'roberta.encoder.layer.7.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.9.crossattention.self.value.weight', 'roberta.encoder.layer.0.crossattention.self.query.weight', 'roberta.encoder.layer.1.crossattention.self.value.weight', 'roberta.encoder.layer.10.crossattention.self.query.bias', 'roberta.encoder.layer.11.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.4.crossattention.self.value.bias', 'roberta.encoder.layer.4.crossattention.self.key.bias', 'roberta.encoder.layer.7.crossattention.self.key.weight', 'roberta.encoder.layer.6.crossattention.self.value.weight', 'roberta.encoder.layer.6.crossattention.self.key.bias', 'roberta.encoder.layer.9.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.9.crossattention.self.key.weight', 'roberta.encoder.layer.1.crossattention.output.dense.weight', 'roberta.encoder.layer.3.crossattention.self.query.weight', 'roberta.encoder.layer.3.crossattention.self.key.bias', 'roberta.encoder.layer.5.crossattention.output.dense.bias', 'roberta.encoder.layer.0.crossattention.output.dense.weight', 'roberta.encoder.layer.7.crossattention.self.query.bias', 'roberta.encoder.layer.8.crossattention.output.dense.bias', 'roberta.encoder.layer.8.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.2.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.8.crossattention.self.key.bias', 'roberta.encoder.layer.5.crossattention.self.value.weight', 'roberta.encoder.layer.3.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.5.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.5.crossattention.self.key.bias', 'roberta.encoder.layer.3.crossattention.self.query.bias', 'roberta.encoder.layer.10.crossattention.self.value.bias', 'roberta.encoder.layer.9.crossattention.self.value.bias', 'roberta.encoder.layer.8.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.1.crossattention.self.value.bias', 'roberta.encoder.layer.3.crossattention.self.key.weight', 'roberta.encoder.layer.10.crossattention.self.key.weight', 'roberta.encoder.layer.8.crossattention.output.dense.weight', 'roberta.encoder.layer.8.crossattention.self.value.weight', 'roberta.encoder.layer.6.crossattention.output.dense.weight', 'roberta.encoder.layer.0.crossattention.self.value.bias', 'roberta.encoder.layer.10.crossattention.output.dense.weight', 'roberta.encoder.layer.4.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.11.crossattention.output.dense.bias', 'roberta.encoder.layer.2.crossattention.self.value.weight', 'roberta.encoder.layer.1.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.5.crossattention.self.query.bias', 'roberta.encoder.layer.11.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.5.crossattention.self.query.weight', 'roberta.encoder.layer.9.crossattention.output.dense.bias', 'roberta.encoder.layer.7.crossattention.self.key.bias', 'roberta.encoder.layer.4.crossattention.self.value.weight', 'roberta.encoder.layer.11.crossattention.self.value.bias', 'roberta.encoder.layer.5.crossattention.output.dense.weight', 'roberta.encoder.layer.1.crossattention.self.key.weight', 'roberta.encoder.layer.0.crossattention.self.value.weight', 'roberta.encoder.layer.2.crossattention.output.dense.bias', 'roberta.encoder.layer.8.crossattention.self.query.bias', 'roberta.encoder.layer.7.crossattention.self.value.bias', 'roberta.encoder.layer.10.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.10.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.7.crossattention.self.value.weight', 'roberta.encoder.layer.2.crossattention.output.dense.weight', 'roberta.encoder.layer.1.crossattention.self.query.bias', 'roberta.encoder.layer.0.crossattention.self.query.bias', 'roberta.encoder.layer.3.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.6.crossattention.self.key.weight', 'roberta.encoder.layer.1.crossattention.output.dense.bias', 'roberta.encoder.layer.9.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.3.crossattention.self.value.bias', 'roberta.encoder.layer.8.crossattention.self.query.weight', 'roberta.encoder.layer.9.crossattention.self.query.bias', 'roberta.encoder.layer.0.crossattention.output.dense.bias', 'roberta.encoder.layer.0.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.4.crossattention.self.key.weight', 'roberta.encoder.layer.10.crossattention.output.dense.bias', 'roberta.encoder.layer.6.crossattention.output.dense.bias', 'roberta.encoder.layer.8.crossattention.self.value.bias', 'roberta.encoder.layer.7.crossattention.self.query.weight', 'roberta.encoder.layer.9.crossattention.output.dense.weight', 'roberta.encoder.layer.5.crossattention.self.key.weight', 'roberta.encoder.layer.10.crossattention.self.value.weight', 'roberta.encoder.layer.11.crossattention.self.value.weight', 'roberta.encoder.layer.8.crossattention.self.key.weight', 'roberta.encoder.layer.2.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.1.crossattention.self.key.bias', 'roberta.encoder.layer.0.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.2.crossattention.self.key.weight', 'roberta.encoder.layer.6.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.1.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.5.crossattention.self.value.bias', 'roberta.encoder.layer.0.crossattention.self.key.weight', 'roberta.encoder.layer.5.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.3.crossattention.output.dense.bias', 'roberta.encoder.layer.7.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.9.crossattention.self.key.bias', 'roberta.encoder.layer.11.crossattention.self.query.bias', 'roberta.encoder.layer.6.crossattention.self.query.bias', 'roberta.encoder.layer.2.crossattention.self.value.bias', 'roberta.encoder.layer.7.crossattention.output.dense.weight', 'roberta.encoder.layer.2.crossattention.self.query.bias', 'roberta.encoder.layer.2.crossattention.self.query.weight', 'roberta.encoder.layer.4.crossattention.output.dense.bias', 'roberta.encoder.layer.4.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.11.crossattention.self.key.bias', 'roberta.encoder.layer.10.crossattention.self.key.bias', 'roberta.encoder.layer.10.crossattention.self.query.weight', 'roberta.encoder.layer.7.crossattention.output.dense.bias', 'roberta.encoder.layer.11.crossattention.self.query.weight', 'roberta.encoder.layer.4.crossattention.self.query.bias', 'roberta.encoder.layer.3.crossattention.self.value.weight', 'roberta.encoder.layer.4.crossattention.self.query.weight', 'roberta.encoder.layer.9.crossattention.self.query.weight', 'roberta.encoder.layer.6.crossattention.self.value.bias', 'roberta.encoder.layer.3.crossattention.output.dense.weight', 'roberta.encoder.layer.4.crossattention.output.dense.weight', 'roberta.encoder.layer.6.crossattention.output.LayerNorm.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","INFO:simpletransformers.seq2seq.seq2seq_utils: Creating features from dataset file at cache_dir/\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"155c4b81324f4c539d70072647b3f37b","version_minor":0,"version_major":2},"text/plain":["  0%|          | 0/8500 [00:00<?, ?it/s]"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["INFO:simpletransformers.seq2seq.seq2seq_utils: Saving features into cached file cache_dir/roberta-base-vinai_phobert-base_cached_108500\n","INFO:simpletransformers.seq2seq.seq2seq_model: Training started\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5d76863eaa34404aa8bdc8e3e147af4c","version_minor":0,"version_major":2},"text/plain":["Epoch:   0%|          | 0/2 [00:00<?, ?it/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b1c4838f3abd453f98d734ca7244d2e8","version_minor":0,"version_major":2},"text/plain":["Running Epoch 0 of 2:   0%|          | 0/67 [00:00<?, ?it/s]"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:524: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n","  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"84eef620dc16401b85f54731339a6f14","version_minor":0,"version_major":2},"text/plain":["Running Epoch 1 of 2:   0%|          | 0/67 [00:00<?, ?it/s]"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["INFO:simpletransformers.seq2seq.seq2seq_model:Saving model into outputs/\n","INFO:simpletransformers.seq2seq.seq2seq_model: Training of roberta-base-vinai/phobert-base model complete. Saved to outputs/.\n"]},{"output_type":"execute_result","data":{"text/plain":["(134, 1.1447084008259074)"]},"metadata":{},"execution_count":48}]}]}